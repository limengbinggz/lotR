weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1,1),b=c(1,1),
tau_update_levels = c(1,2),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# still haven't fixed monotinicity :(/
source("inst/example/lotR_example.R")
V(thetree_igraph)$levels       <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[c(1)] <- 1
# V(thetree_igraph)$levels <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[match(names(igraph::V(thetree_igraph)[igraph::degree(thetree_igraph, mode = "out") == 0]),
#                               names(igraph::V(thetree_igraph)))] <- 2
# V(thetree_igraph)$levels[1] <- 3 # separate rootnode.
tau   <- c(0.5,0.3,0.2)
theta <- rbind(rep(rep(c(0.01, 0.01), each = 1),9),
rep(rep(c(0.5, 0.5), each = 1),9),
rep(rep(c(0.9, 0.9), each = 1),9))
image(t(theta))
#
# simulated data
#
Y <- BayesLCA::rlca(2663, itemprob = theta, classprob = tau)
curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
## five times more: () <---------- is it possible that the order of the outcomes matter in
## terms of estimation. Clean the code and push to github.
# Y <- BayesLCA::rlca(2663*5, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"])
#
## two times more:
Y <- BayesLCA::rlca(2663*2, itemprob = theta, classprob = tau)
curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],
dat_mge[!is.na(match_ind),"ct_MLST"]
)
#
# real data:
#
# Y <- dat_mge[!is.na(match_ind),ind_EL]
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
K     <- length(tau)
p     <- length(V(thetree_igraph))
J     <- ncol(Y)
dsgn0  <- design_tree(Y,curr_leaves,thetree_igraph,root_node = "Node1",weighted_edge = FALSE)
nrestarts <- 1
log_dir <- "restart_logs"
dir.create(log_dir)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1),b=c(1),
tau_update_levels = c(1),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,1),
tau_2=rep(9/4,1)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
# closeAllConnections()
# summarize posterior results:
plot(mod0)
#image(mod0$prob_est$pi_collapsed)
mod0$prob_est$pi_collapsed
library(lotR)
# still haven't fixed monotinicity :(/
source("inst/example/lotR_example.R")
V(thetree_igraph)$levels       <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[c(1)] <- 1
# V(thetree_igraph)$levels <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[match(names(igraph::V(thetree_igraph)[igraph::degree(thetree_igraph, mode = "out") == 0]),
#                               names(igraph::V(thetree_igraph)))] <- 2
# V(thetree_igraph)$levels[1] <- 3 # separate rootnode.
tau   <- c(0.5,0.3,0.2)
theta <- rbind(rep(rep(c(0.01, 0.01), each = 1),9),
rep(rep(c(0.5, 0.5), each = 1),9),
rep(rep(c(0.9, 0.9), each = 1),9))
image(t(theta))
#
# simulated data
#
Y <- BayesLCA::rlca(2663, itemprob = theta, classprob = tau)
curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
## five times more: () <---------- is it possible that the order of the outcomes matter in
## terms of estimation. Clean the code and push to github.
# Y <- BayesLCA::rlca(2663*5, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"])
#
## two times more:
Y <- BayesLCA::rlca(2663*2, itemprob = theta, classprob = tau)
curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],
dat_mge[!is.na(match_ind),"ct_MLST"]
)
#
# real data:
#
# Y <- dat_mge[!is.na(match_ind),ind_EL]
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
K     <- length(tau)
p     <- length(V(thetree_igraph))
J     <- ncol(Y)
dsgn0  <- design_tree(Y,curr_leaves,thetree_igraph,root_node = "Node1",weighted_edge = FALSE)
nrestarts <- 1
log_dir <- "restart_logs"
dir.create(log_dir)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1),b=c(1),
tau_update_levels = c(1),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,1),
tau_2=rep(9/4,1)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
# closeAllConnections()
# summarize posterior results:
plot(mod0)
#image(mod0$prob_est$pi_collapsed)
mod0$prob_est$pi_collapsed
load("~/Dropbox/ZW/professional/git/lotR/151_101.rdata")
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1,1),b=c(1,1),
tau_update_levels = c(1,2),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1,1),b=c(1,1),
tau_update_levels = c(1,2),
#s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
library(lotR)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1,1),b=c(1,1),
tau_update_levels = c(1,2),
#s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1,1),b=c(1,1),
tau_update_levels = c(1,2),
#s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1,1),b=c(1,1),
tau_update_levels = c(1,2),
#s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
# still haven't fixed monotinicity :(/
source("inst/example/lotR_example.R")
V(thetree_igraph)$levels       <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[c(1)] <- 1
# V(thetree_igraph)$levels <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[match(names(igraph::V(thetree_igraph)[igraph::degree(thetree_igraph, mode = "out") == 0]),
#                               names(igraph::V(thetree_igraph)))] <- 2
# V(thetree_igraph)$levels[1] <- 3 # separate rootnode.
tau   <- c(0.5,0.3,0.2)
theta <- rbind(rep(rep(c(0.01, 0.01), each = 1),9),
rep(rep(c(0.5, 0.5), each = 1),9),
rep(rep(c(0.9, 0.9), each = 1),9))
image(t(theta))
#
# simulated data
#
# Y <- BayesLCA::rlca(2663, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
## five times more: () <---------- is it possible that the order of the outcomes matter in
## terms of estimation. Clean the code and push to github.
# Y <- BayesLCA::rlca(2663*5, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"])
#
## two times more:
# Y <- BayesLCA::rlca(2663*2, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"]
#                  )
#
# real data:
#
Y <- dat_mge[!is.na(match_ind),ind_EL]
curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
K     <- length(tau)
p     <- length(V(thetree_igraph))
J     <- ncol(Y)
dsgn0  <- design_tree(Y,curr_leaves,thetree_igraph,root_node = "Node1",weighted_edge = FALSE)
nrestarts <- 1
log_dir <- "restart_logs"
dir.create(log_dir)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1,1),b=c(1,1),
tau_update_levels = c(2),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
# closeAllConnections()
# summarize posterior results:
plot(mod0)
#image(mod0$prob_est$pi_collapsed)
mod0$prob_est$pi_collapsed
# still haven't fixed monotinicity :(/
source("inst/example/lotR_example.R")
V(thetree_igraph)$levels       <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[c(1)] <- 1
# V(thetree_igraph)$levels <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[match(names(igraph::V(thetree_igraph)[igraph::degree(thetree_igraph, mode = "out") == 0]),
#                               names(igraph::V(thetree_igraph)))] <- 2
# V(thetree_igraph)$levels[1] <- 3 # separate rootnode.
tau   <- c(0.5,0.3,0.2)
theta <- rbind(rep(rep(c(0.01, 0.01), each = 1),9),
rep(rep(c(0.5, 0.5), each = 1),9),
rep(rep(c(0.9, 0.9), each = 1),9))
image(t(theta))
#
# simulated data
#
# Y <- BayesLCA::rlca(2663, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
## five times more: () <---------- is it possible that the order of the outcomes matter in
## terms of estimation. Clean the code and push to github.
# Y <- BayesLCA::rlca(2663*5, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"])
#
## two times more:
# Y <- BayesLCA::rlca(2663*2, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"]
#                  )
#
# real data:
#
Y <- dat_mge[!is.na(match_ind),ind_EL]
curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
K     <- length(tau)
p     <- length(V(thetree_igraph))
J     <- ncol(Y)
dsgn0  <- design_tree(Y,curr_leaves,thetree_igraph,root_node = "Node1",weighted_edge = FALSE)
nrestarts <- 1
log_dir <- "restart_logs"
dir.create(log_dir)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1),b=c(1),
tau_update_levels = c(99),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4,2),
tau_2=rep(9/4,2)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
# closeAllConnections()
# summarize posterior results:
plot(mod0)
#image(mod0$prob_est$pi_collapsed)
mod0$prob_est$pi_collapsed
# still haven't fixed monotinicity :(/
source("inst/example/lotR_example.R")
V(thetree_igraph)$levels       <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[c(1)] <- 1
# V(thetree_igraph)$levels <- rep(1,length(V(thetree_igraph)))
# V(thetree_igraph)$levels[match(names(igraph::V(thetree_igraph)[igraph::degree(thetree_igraph, mode = "out") == 0]),
#                               names(igraph::V(thetree_igraph)))] <- 2
# V(thetree_igraph)$levels[1] <- 3 # separate rootnode.
tau   <- c(0.5,0.3,0.2)
theta <- rbind(rep(rep(c(0.01, 0.01), each = 1),9),
rep(rep(c(0.5, 0.5), each = 1),9),
rep(rep(c(0.9, 0.9), each = 1),9))
image(t(theta))
#
# simulated data
#
# Y <- BayesLCA::rlca(2663, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
## five times more: () <---------- is it possible that the order of the outcomes matter in
## terms of estimation. Clean the code and push to github.
# Y <- BayesLCA::rlca(2663*5, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"],dat_mge[!is.na(match_ind),"ct_MLST"])
#
## two times more:
# Y <- BayesLCA::rlca(2663*2, itemprob = theta, classprob = tau)
# curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"],
#                  dat_mge[!is.na(match_ind),"ct_MLST"]
#                  )
#
# real data:
#
Y <- dat_mge[!is.na(match_ind),ind_EL]
curr_leaves <- c(dat_mge[!is.na(match_ind),"ct_MLST"])
K     <- length(tau)
p     <- length(V(thetree_igraph))
J     <- ncol(Y)
dsgn0  <- design_tree(Y,curr_leaves,thetree_igraph,root_node = "Node1",weighted_edge = FALSE)
nrestarts <- 1
log_dir <- "restart_logs"
dir.create(log_dir)
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1),b=c(1),
tau_update_levels = c(99),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(9/4),
tau_2=rep(9/4)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
# closeAllConnections()
# summarize posterior results:
plot(mod0)
#image(mod0$prob_est$pi_collapsed)
mod0$prob_est$pi_collapsed
set.seed(345083)
par(mfrow=c(3,3));plot(0,0)
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1),b=c(1),
tau_update_levels = c(99),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(90/4),
tau_2=rep(90/4)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
# unlink(log_dir, recursive = T)
# closeAllConnections()
mod0     <- lcm_tree(Y,curr_leaves,thetree_igraph,
rootnode      = "Node1", # <-- may be redundant?
weighted_edge = !TRUE,
hyper_fixed   = list(K=K,a=c(1),b=c(1),
tau_update_levels = c(99),
s_u_zeroset = NULL,s_u_oneset = NULL),
#s_u_zeroset = (1:265)[-c(1,2,3,4,76,120)],s_u_oneset = c(1,2,3,4,76,120)),
#s_u_zeroset = (1:265)[-c(1)],s_u_oneset = c(1)),
hyperparams_init = list(tau_1=rep(900/4),
tau_2=rep(900/4)),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=2,ncol=K-1),
#                         tau_2=aperm(array(c(rep(9/4,J*K),
#                                             rep(9/4,J*K)),c(J,K,2)),
#                                     c(3,1,2))),
# hyperparams_init = list(tau_1=matrix(9/4,nrow=1,ncol=K-1),
#                         tau_2=array(9/4,c(1,J,K))),
nrestarts     = nrestarts,
print_freq = 1,update_hyper_freq = 50, max_iter = 200,
allow_continue = FALSE,log_restarts = !TRUE, log_dir = log_dir)
